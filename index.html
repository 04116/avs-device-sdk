<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>AlexaClientSDK: IMPORTANT NOTE</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="avs-logo.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">AlexaClientSDK
   &#160;<span id="projectnumber">1.5.0</span>
   </div>
   <div id="projectbrief">A cross-platform, modular SDK for interacting with the Alexa Voice Service</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0"
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">IMPORTANT NOTE </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>If you are updating from v1.3 or earlier to v1.5, you must update your <code>AlexaClientSDKConfig.json</code> to include a Notifications database. An updated sample is available in the quickstart guides for Ubuntu Linux, Raspberry Pi, macOS, and Generic Linux.</p>
<h3>What is the Alexa Voice Service (AVS)?</h3>
<p>The Alexa Voice Service (AVS) enables developers to integrate Alexa directly into their products, bringing the convenience of voice control to any connected device. AVS provides developers with access to a suite of resources to quickly and easily build Alexa-enabled products, including APIs, hardware development kits, software development kits, and documentation.</p>
<p><a href="https://developer.amazon.com/alexa-voice-service">Learn more Â»</a></p>
<h3>Overview of the AVS Device SDK</h3>
<p>The AVS Device SDK provides C++-based (11 or later) libraries that leverage the AVS API to create device software for Alexa-enabled products. It is modular and abstracted, providing components for handling discrete functions such as speech capture, audio processing, and communications, with each component exposing the APIs that you can use and customize for your integration. It also includes a sample app, which demonstrates the interactions with AVS.</p>
<h3>Get Started</h3>
<p>You can set up the SDK on the following platforms:</p><ul>
<li><a href="https://github.com/alexa/avs-device-sdk/wiki/Ubuntu-Linux-Quick-Start-Guide">Ubuntu Linux</a></li>
<li><a href="https://github.com/alexa/avs-device-sdk/wiki/Raspberry-Pi-Quick-Start-Guide-with-Script">Raspberry Pi</a> (Raspbian Stretch)</li>
<li><a href="https://github.com/alexa/avs-device-sdk/wiki/macOS-Quick-Start-Guide">macOS</a></li>
<li><a href="https://github.com/alexa/avs-device-sdk/wiki/Linux-Reference-Guide">Generic Linux</a></li>
</ul>
<p>You can also prototype with a third party development kit:</p><ul>
<li><a href="https://github.com/xmos/vocalfusion-avs-setup">xCORE VocalFusion 4-Mic Kit</a></li>
<li><a href="https://www.nxp.com/docs/en/user-guide/Quick-Start-Guide-for-Arrow-AVS-kit.pdf">NXP PICO-PI-IMX7D 2-Mic Kit</a></li>
</ul>
<p>Or if you prefer, you can start with our <a href="https://alexa.github.io/avs-device-sdk/">SDK API Documentation</a>.</p>
<h3>Learn More About The AVS Device SDK</h3>
<p><a href="https://youtu.be/F5DixCPJYo8">Watch this tutorial</a> to learn about the how this SDK works and the set up process.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/F5DixCPJYo8" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
<h3>SDK Architecture</h3>
<p>This diagram illustrates the data flows between components that comprise the AVS Device SDK for C++.</p>
<div class="image">
<img src="https://m.media-amazon.com/images/G/01/mobile-apps/dex/avs/Alexa_Device_SDK_Architecture.png" alt="SDK Architecture Diagram"/ width="75%">
</div>
<p><b>Audio Signal Processor (ASP)</b> - Third-party software that applies signal processing algorithms to both input and output audio channels. The applied algorithms are designed to produce clean audio data and include, but are not limited to acoustic echo cancellation (AEC), beam forming (fixed or adaptive), voice activity detection (VAD), and dynamic range compression (DRC). If a multi-microphone array is present, the ASP constructs and outputs a single audio stream for the array.</p>
<p><b>Shared Data Stream (SDS)</b> - A single producer, multi-consumer buffer that allows for the transport of any type of data between a single writer and one or more readers. SDS performs two key tasks:</p>
<ol type="1">
<li>It passes audio data between the audio front end (or Audio Signal Processor), the wake word engine, and the Alexa Communications Library (ACL) before sending to AVS</li>
<li>It passes data attachments sent by AVS to specific capability agents via the ACL</li>
</ol>
<p>SDS is implemented atop a ring buffer on a product-specific memory segment (or user-specified), which allows it to be used for in-process or interprocess communication. Keep in mind, the writer and reader(s) may be in different threads or processes.</p>
<p><b>Wake Word Engine (WWE)</b> - Software that spots wake words in an input stream. It is comprised of two binary interfaces. The first handles wake word spotting (or detection), and the second handles specific wake word models (in this case "Alexa"). Depending on your implementation, the WWE may run on the system on a chip (SOC) or dedicated chip, like a digital signal processor (DSP).</p>
<p><b>Audio Input Processor (AIP)</b> - Handles audio input that is sent to AVS via the ACL. These include on-device microphones, remote microphones, an other audio input sources.</p>
<p>The AIP also includes the logic to switch between different audio input sources. Only one audio input source can be sent to AVS at a given time.</p>
<p><b>Alexa Communications Library (ACL)</b> - Serves as the main communications channel between a client and AVS. The ACL performs two key functions:</p>
<ol type="1">
<li>Establishes and maintains long-lived persistent connections with AVS. ACL adheres to the messaging specification detailed in <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/docs/managing-an-http-2-connection">Managing an HTTP/2 Connection with AVS</a>.</li>
<li>Provides message sending and receiving capabilities, which includes support JSON-formatted text, and binary audio content. For additional information, see <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/docs/avs-http2-requests">Structuring an HTTP/2 Request to AVS</a>.</li>
</ol>
<p><b>Alexa Directive Sequencer Library (ADSL)</b>: Manages the order and sequence of directives from AVS, as detailed in the <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/interaction-model#channels">AVS Interaction Model</a>. This component manages the lifecycle of each directive, and informs the Directive Handler (which may or may not be a Capability Agent) to handle the message.</p>
<p><b>Activity Focus Manager Library (AFML)</b>: Provides centralized management of audiovisual focus for the device. Focus is based on channels, as detailed in the <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/interaction-model#channels">AVS Interaction Model</a>, which are used to govern the prioritization of audiovisual inputs and outputs.</p>
<p>Channels can either be in the foreground or background. At any given time, only one channel can be in the foreground and have focus. If multiple channels are active, you need to respect the following priority order: Dialog &gt; Alerts &gt; Content. When a channel that is in the foreground becomes inactive, the next active channel in the priority order moves into the foreground.</p>
<p>Focus management is not specific to Capability Agents or Directive Handlers, and can be used by non-Alexa related agents as well. This allows all agents using the AFML to have a consistent focus across a device.</p>
<p><b>Capability Agents</b>: Handle Alexa-driven interactions; specifically directives and events. Each capability agent corresponds to a specific interface exposed by the AVS API. These interfaces include:</p>
<ul>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/speechrecognizer">SpeechRecognizer</a> - The interface for speech capture.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/speechsynthesizer">SpeechSynthesizer</a> - The interface for Alexa speech output.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/alerts">Alerts</a> - The interface for setting, stopping, and deleting timers and alarms.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/audioplayer">AudioPlayer</a> - The interface for managing and controlling audio playback.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/notifications">Notifications</a> - The interface for displaying notifications indicators.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/playbackcontroller">PlaybackController</a> - The interface for navigating a playback queue via GUI or buttons.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/speaker">Speaker</a> - The interface for volume control, including mute and unmute.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/system">System</a> - The interface for communicating product status/state to AVS.</li>
<li><a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/reference/templateruntime">TemplateRuntime</a> - The interface for rendering visual metadata.</li>
</ul>
<h3>Important Considerations</h3>
<ul>
<li>Review the AVS <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/support/terms-and-agreements">Terms &amp; Agreements</a>.</li>
<li>The earcons associated with the sample project are for <b>prototyping purposes</b> only. For implementation and design guidance for commercial products, please see <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/content/designing-for-the-alexa-voice-service">Designing for AVS</a> and <a href="https://developer.amazon.com/public/solutions/alexa/alexa-voice-service/content/alexa-voice-service-ux-design-guidelines">AVS UX Guidelines</a>.</li>
<li>Please use the contact information below to-<ul>
<li><a href="http://www.sensory.com/support/contact/us-sales/">Contact Sensory</a> for information on TrulyHandsFree licensing.</li>
<li><a href="#" onclick="location.href='mai'+'lto:'+'sno'+'wb'+'oy@'+'ki'+'tt.'+'ai'; return false;">Contact KITT.AI</a> for information on SnowBoy licensing.</li>
</ul>
</li>
<li><b>IMPORTANT</b>: The Sensory wake word engine referenced in this document is time-limited: code linked against it will stop working when the library expires. The library included in this repository will, at all times, have an expiration date that is at least 120 days in the future. See <a href="https://github.com/Sensory/alexa-rpi#license">Sensory's GitHub</a>page for more information.</li>
</ul>
<h3>Release Notes and Known Issues</h3>
<p><b>Note</b>: Feature enhancements, updates, and resolved issues from previous releases are available to view in https://github.com/alexa/alexa-client-sdk/blob/master/CHANGELOG.md "CHANGELOG.md".</p>
<p>v1.5.0 released 02/12/2018:</p>
<p><b>Enhancements</b></p><ul>
<li>Added the <code>ExternalMediaPlayer</code> Capability Agent. This allows playback from music providers that control their own playback queue. Example: Spotify.</li>
<li>Added support for AU and NZ to the <code>SampleApp</code>.</li>
<li>Firmware version can now be sent to Alexa via the <code>SoftwareInfo</code> event. The firmware version is specified in the config file under the <code>sampleApp</code> object as an integer value named <a href="https://github.com/alexa/avs-device-sdk/blob/master/Integration/AlexaClientSDKConfig.json#L52"><code>firmwareVersion</code></a>.</li>
<li>The new <code>f</code> command was added to the <code>SampleApp</code> which allows the firmware version to be updated at run-time.</li>
<li>Optional configuration changes have been introduced. Now a <a href="https://github.com/alexa/avs-device-sdk/blob/master/Integration/AlexaClientSDKConfig.json#L93">default log level</a> can be set for <code>ACSDK_LOG_MODULE</code> components, globally or individually. This value is specified under a new root level configuration object called <code>logger</code>, and the value itself is named <code>logLevel</code>. This allows you to limit the degree of logging to that default value, such as <code>ERROR</code>or <code>INFO</code>.</li>
</ul>
<p><b>Bug Fixes</b></p><ul>
<li>Fixed bug where <code>AudioPlayer</code> progress reports were not being sent, or were being sent incorrectly.</li>
<li><a href="https://github.com/alexa/avs-device-sdk/issues/408">Issue 408</a> - Irrelevant code related to <code>UrlSource</code> was removed from the <code>GStreamer-based MediaPlayer</code> implementation.</li>
<li>The <code>TZ</code> variable no longer needs to be set to <code>UTC</code> when building the <code>SampleApp</code>.</li>
<li>Fixed a bug where <code>CurlEasyHandleWrapper</code> logged unwanted data on failure conditions.</li>
<li>Fixed a bug to improve <code>SIGPIPE</code> handling.</li>
<li>Fixed a bug where the filename and classname were mismatched. Changed <code>UrlToAttachmentConverter.h</code> to <code><a class="el" href="_url_content_to_attachment_converter_8h.html">UrlContentToAttachmentConverter.h</a></code>,and <code>UrlToAttachmentConverter.cpp</code> to <code><a class="el" href="_url_content_to_attachment_converter_8cpp.html">UrlContentToAttachmentConverter.cpp</a></code></li>
</ul>
<p><b>Known Issues</b></p><ul>
<li>The <code>ACL</code> may encounter issues if audio attachments are received but not consumed.</li>
<li>Display Cards for Kindle don't render.</li>
<li>If using the GStreamer-based <code>MediaPlayer</code> implementation, after muting and un-muting an audio item, the next item in the queue will begin playing rather than continuing playback of the originally muted audio item.</li>
<li><code>SpeechSynthesizerState</code> currently uses <code>GAINING_FOCUS</code> and <code>LOSING_FOCUS</code> as a workaround for handling intermediate state. These states may be removed in a future release.</li>
<li>Music playback doesn't immediately stop when a user barges-in on iHeartRadio. </li>
</ul>
</div></div><!-- contents -->
<html>
  <body>
    <p style="text-align:left;">
      AlexaClientSDK 1.5.0 - Copyright 2016-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
      <span style="float:right;">
	Licensed under the <a HREF=http://aws.amazon.com/apache2.0/>Apache License, Version 2.0</a>
      </span>
    </p>
  </body>
</html>
